---
title: "Clustering Powerlifting"
author: "Pedro Lins M. M. C."
date: "`r Sys.Date()`"
output: html_document
---


```{r, echo=TRUE, include=FALSE}
############
# Packages #
############

library(plyr)
library(gapminder)
library(tidyverse)
library(knitr)
library(ggplot2)
library(caret) 
library(mltools)
library(data.table) #one hot encode table
library(ggcorrplot) 
library(factoextra) #plot cluster
library(cluster) #cluster
library(dbscan)
library(gridExtra)
library(fpc)

```

```{r}
#############
# Load Data #
#############
openpowerlifting = "openpowerlifting.csv" 
df = read_csv(openpowerlifting)
```

```{r}
#####################
# Checking the data #
#####################
#understand the quirks of the data set and potential errors
# summary(df) #checking data
# head(df)

# I did it because date was in DD/MM/YYYY format, to make it easier for analyse, I made it just YYYY. 
df$Year = c(format(df$Date, "%Y"))
df$Year = as.numeric(df$Year)

#adding the percentage of each lift from the total
df$sq = df$Best3SquatKg/df$TotalKg
df$bp = df$Best3BenchKg/df$TotalKg
df$dl = df$Best3DeadliftKg/df$TotalKg
```


```{r}
df2 = df %>%
  filter(Year > 2018) %>%
  filter(Equipment == "Raw") %>%
  filter(Event == "SBD") %>%
  filter(ParentFederation == "IPF") %>%
  filter(Squat1Kg > 0) %>%
  filter(Squat2Kg > 0) %>%
  filter(Squat3Kg > 0) %>%
  filter(Bench1Kg > 0) %>%
  filter(Bench2Kg > 0) %>%
  filter(Bench3Kg > 0) %>%
  filter(Deadlift1Kg > 0) %>%
  filter(Deadlift2Kg > 0) %>%
  filter(Deadlift3Kg > 0) 

df2=df2[c(28,33,43:45)]
df2=na.omit(df2)
#leave only the percentages from the total
df3 = df2[c(3:5)]
#remove NA's
df3 = na.omit(df3)
#normilize data
df3 = scale(df3)
#from list to dataframe
df3 = as.data.frame(df3)

```

```{r}
###########
# K-means # 
###########

#set.seed(123) #para resultados ser replicaveis já que o kmeans inicia escolhendo pontos aleatórios
#df3 = slice_sample(df3, n = 2000, replace = TRUE) #usaremos uma amostra pois o banco de dados é muito grande

# Elbow method
#fviz_nbclust(x = df3, FUNcluster = kmeans,method = "wss") + labs(subtitle = "Elbow method") #avaliar melhor número de clusters

# Silhouette method
fviz_nbclust(df3, kmeans, method = "silhouette")+
  labs(subtitle = "Silhouette method") # outro método de avaliar número de clusters

# Viz
#set.seed(112) #para resultados ser replicaveis já que o kmeans inicia escolhendo pontos aleatórios
km.res <- eclust(df3, "kmeans", k = 3, nstart = 100, graph = FALSE) #rodar modelo

# Validation
#fviz_silhouette(km.res, palette = "jco", ggtheme = theme_classic()) #avaliar se o k escolhido está bom

#Visualizar clusterização
fviz_cluster(km.res, geom = "point", ellipse.type = "norm",palette = "jco", ggtheme = theme_minimal()) 

km.res
```


```{r}
df2$cluster =km.res$cluster

ggplot(df2%>%count(Country)%>%arrange(desc(n))%>%slice(1:10), aes(x = reorder(Country, -n), y = n))+
  geom_bar(stat='identity', fill = "blue", alpha = 0.7)

# Specify data column
means = aggregate(x= df2$cluster,   
            
         # Specify group indicator
         by = list(df2$Country),      
            
         # Specify function (i.e. mean)
         FUN = mean)
df2$cluster = as.character(df2$cluster)

ggplot(df2, aes(x = Dots, fill = cluster))+
  labs(title = 'Dots distribution per cluster')+
  geom_boxplot()+
  theme_minimal()

ggplot(df2, aes(x = Dots, fill = cluster))+
  labs(title = 'Number of athletes on each cluster')+
  geom_histogram()+
  theme_minimal()
```



```{r}
library(mltools)
library(data.table)

df2$cluster <- as.factor(df2$cluster)
newdata <- one_hot(as.data.table(df2))

# Specify data column
dftemp1 = aggregate(x= newdata$cluster_1,   
            
         # Specify group indicator
         by = list(df2$Country),      
            
         # Specify function (i.e. mean)
         FUN = mean)

dftemp2 = aggregate(x= newdata$cluster_2,   
            
         # Specify group indicator
         by = list(df2$Country),      
            
         # Specify function (i.e. mean)
         FUN = mean)
dftemp3 = aggregate(x= newdata$cluster_3,   
            
         # Specify group indicator
         by = list(df2$Country),      
            
         # Specify function (i.e. mean)
         FUN = mean)

dftemp = data.frame(dftemp1,dftemp2,dftemp3)
dftemp = dftemp[-c(3,5)]


cluster1 = dftemp %>%
  filter(x>x.1) %>%
  filter(x>x.2)
cluster1$cluster = c(1)

cluster2 = dftemp %>%
  filter(x.1>x) %>%
  filter(x.1>x.2)
cluster2$cluster = c(2)

cluster3 = dftemp %>%
  filter(x.2>x) %>%
  filter(x.2>x.1)
cluster3$cluster = c(3)

df_final = rbind(cluster1, cluster2, cluster3)
write.csv(df_final,"Countriesbycluster.csv", row.names = TRUE)
```

```{r}
library(magrittr)
library(ggmap)
library(stringr)

map.world <- map_data("world")

# LEFT JOIN
map.world_joined <- left_join(map.world, df_final, by = c('region' = 'Group.1'))

df_final$cluster = as.character(df_final$cluster)

ggplot() +
  geom_polygon(data = map.world_joined, aes(x = long, y = lat, group = group, fill = cluster)) +
  labs(title = 'Countries by cluster') +
  theme_minimal()
```